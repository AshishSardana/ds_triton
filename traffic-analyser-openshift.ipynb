{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZcFtRsZTluK"
   },
   "source": [
    "<img src=\"http://developer.download.nvidia.com/compute/machine-learning/frameworks/nvidia_logo.png\" width=60 height=60 align=\"left\"/>\n",
    "<img src=\"https://info.nvidia.com/rs/156-OFN-742/images/Red_Hat_new_BW.jpg\" width=100 height=100 align=\"left\"/>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "# Deploying Traffic Analyser IVA application using NVIDIA Metropolis platform in OCP Kubernetes cluster environment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIvp7M8fTluL"
   },
   "source": [
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to: \n",
    "1. Setup OpenShift cluster on AWS and run GPU Operator\n",
    "2. Pull pre-trained TAO models from NGC\n",
    "3. Optimize the model with Nvidia TensorRT\n",
    "4. Scale the DeepStream-Triton application on OCP kubernetes cluster\n",
    "5. Observe inference throughput on 8 A100 GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rYGBiHu6TluM"
   },
   "source": [
    "## Requirements\n",
    "\n",
    "- NVIDIA GPU \n",
    "  - A100 (p4d instance on AWS)\n",
    "- OpenShift Platform\n",
    "- Ubuntu system to run this notebook on\n",
    "- Python3 environment to run this notebook in\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8hXortSPjJN",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Links\n",
    "\n",
    "**Nvidia NGC resources**\n",
    "\n",
    "\n",
    "* Model - TrafficCamNet: \n",
    "\n",
    "  https://ngc.nvidia.com/catalog/models/nvidia:tao:trafficcamnet\n",
    "  \n",
    "* Model - VehicleTypeNet: \n",
    "  \n",
    "  https://ngc.nvidia.com/catalog/models/nvidia:tao:vehicletypenet\n",
    "\n",
    "* Container - DeepStream-Triton:\n",
    "\n",
    "  https://ngc.nvidia.com/catalog/containers/nvidia:deepstream\n",
    "\n",
    "\n",
    "**RedHat OpenShift resources**\n",
    "\n",
    "* RedHat OpenShift link\n",
    "\n",
    "  http://openshift.com/\n",
    "\n",
    "* OpenShift operators\n",
    "\n",
    "  https://www.openshift.com/learn/topics/operators\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBP0MAJNTluQ",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Topology of the cluster\n",
    "\n",
    "We will first deploy one OCP cluster without GPU node using the openshift-installer command. This will spawn the following nodes:\n",
    "\n",
    "- 3 x Master nodes (m5.xlarge by default)\n",
    "- 2 x Worker nodes\n",
    "\n",
    "After this, we would add a scale-up node (GPU worker nodes, p4d instance type).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBP0MAJNTluQ"
   },
   "source": [
    "## Setup OpenShift Cluster\n",
    "\n",
    "To setup OpenShift cluster, we would the openshift-install CLI tool to initialise and delete the cluster, as per our requirement.\n",
    "For this demo, we would use AWS to deploy the cluster and hence would require its credentials.\n",
    "\n",
    "Let's run the following commands to setup the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the cli tool\n",
    "!wget https://mirror.openshift.com/pub/openshift-v4/clients/ocp/4.8.11/openshift-install-linux.tar.gz\n",
    "!tar xvf openshift-install-linux.tar.gz\n",
    "\n",
    "# create cluster\n",
    "! ./openshift-install create cluster\n",
    "\n",
    "# enter your aws access and secret keys\n",
    "# select region as \"eu-central-1\"\n",
    "# it will take upto 40 minutes to setup the cluster\n",
    "# keep note of the \"kubeconfig\" which gets generated after the cluster is up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBP0MAJNTluQ",
    "tags": []
   },
   "source": [
    "## Install OpenShift CLI\n",
    "\n",
    "To communicate with this cluster, we will use OpenShift client tool to add A100 nodes and install the GPU operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the tool\n",
    "!wget https://mirror.openshift.com/pub/openshift-v4/clients/ocp/4.8.11/openshift-client-linux.tar.gz\n",
    "!tar xvf openshift-client-linux.tar.gz\n",
    "\n",
    "# move it to another directory\n",
    "!mkdir bin\n",
    "!mv oc bin\n",
    "!export PATH=$PATH:$(pwd)/bin\n",
    "!oc version # to verify that the CLI & cluster can be accessed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add NVIDIA A100 GPU node to the cluster\n",
    "\n",
    "Now that our cluster is up and ready and we have the OpenShift client installed, we will now add a GPU node (p4d instance) to this cluster. This node will be used to run the Traffic Analyser application.\n",
    "\n",
    "Though the worker nodes can be easily added through the GUI, we are going to use utility scripts developed by OpenShift's developers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloning the git repo\n",
    "!git clone https://github.com/kpouget/ci-artifacts -b mig\n",
    "!cd ci-artifacts\n",
    "\n",
    "# install the pip package\n",
    "!pip3 install -r requirements.txt\n",
    "\n",
    "# run the tool\n",
    "!./run_toolbox.py cluster capture_environment # verify that things are correctly setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting variables for aws instance\n",
    "! export P4D_REGION=1b\n",
    "! export MACHINE_TYPE=p4d.24xlarge\n",
    "\n",
    "# getting region's machineset\n",
    "! REGION_MACHINESET=$(oc get machinesets -n openshift-machine-api -oname | grep -- \"$P4D_REGION\"'$' | head -1 | cut -d/ -f2)\n",
    "\n",
    "# running and starting the p4d instance\n",
    "!./run_toolbox.py cluster set_scale \"$MACHINE_TYPE\" 1 --base-machineset=\"${REGION_MACHINESET}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ttW_HixSodUe"
   },
   "outputs": [],
   "source": [
    "# check if there are a total 3 master and 3 worker nodes \n",
    "! oc get nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBP0MAJNTluQ",
    "tags": []
   },
   "source": [
    "## Install NVIDIA GPU Operator\n",
    "\n",
    "To use NVIDIA GPUs on OpenShift, you have to install the NVIDIA GPU Operator. This Operator exposes GPUs to Kubernetes as extended resources that can be requested and exposed into Pods and containers. The GPU Operator is enabling OpenShift cluster administrator to decide the geometry to apply to the MIG-capable GPUs of a node, apply a specific label to this node, and wait for the GPU Operator to reconfigure the GPUs and advertise the new MIG devices as resources to Kubernetes.\n",
    "\n",
    "The instructions to install the NVIDIA GPU Operator on this OpenShift cluster can be followed from the [NVIDIA official page](https://docs.nvidia.com/datacenter/cloud-native/openshift/steps-overview.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBP0MAJNTluQ",
    "tags": []
   },
   "source": [
    "## Enable MIG strategy on A100\n",
    "\n",
    "To use NVIDIA GPUs on OpenShift, you have to install the NVIDIA GPU Operator. This Operator exposes GPUs to Kubernetes as extended resources that can be requested and exposed into Pods and containers. The GPU Operator is enabling OpenShift cluster administrator to decide the geometry to apply to the MIG-capable GPUs of a node, apply a specific label to this node, and wait for the GPU Operator to reconfigure the GPUs and advertise the new MIG devices as resources to Kubernetes.\n",
    "\n",
    "The instructions to install the NVIDIA GPU Operator on this OpenShift cluster can be followed from the [NVIDIA official page.](https://docs.nvidia.com/datacenter/cloud-native/openshift/steps-overview.html) Make sure that the MIG configuration that you select homogeneously for all the GPUs is 2g.10gb as we've found this to be the most performant for this use-case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBP0MAJNTluQ",
    "tags": []
   },
   "source": [
    "## Deploy the Traffic Analyser - Metropolis IVA application\n",
    "\n",
    "Now that our cluster is ready with a 8 x A100 GPU node with the right drivers and operators, we will now deploy the use-case application.\n",
    "\n",
    "We have developed a simple deployment yaml that can be used schedule pods on this cluster. This yaml will execute an automation script which takes care of pulling models and other assets from NGC, optimize them through TensorRT and then execute the video analytics pipeline through DeepStream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a deployment.yaml\n",
    "\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: metropolis\n",
    "spec:\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: ds\n",
    "  replicas: 24\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: ds\n",
    "    spec:\n",
    "      restartPolicy: Always\n",
    "      containers:\n",
    "      - image: nvcr.io/nvidia/deepstream:5.1-21.02-triton\n",
    "        name: cnt\n",
    "        command: [\"/bin/sh\",\"-c\"]\n",
    "        args: [\"git clone https://github.com/AshishSardana/ds_triton.git && cd ds_triton && bash -x automate_script.sh\"]\n",
    "        resources:\n",
    "          limits:\n",
    "            nvidia.com/gpu: 1\n",
    "          requests:\n",
    "            nvidia.com/gpu: 1\n",
    "      nodeSelector:\n",
    "        nvidia.com/gpu.product: NVIDIA-A100-SXM4-40GB-MIG-2g.10gb\n",
    "        nvidia.com/mig.config: all-2g.10gb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would encourage you to read the `automate_script.sh` in this [Github repo](https://github.com/AshishSardana/ds_triton) to understand the workflow in detail.\n",
    "\n",
    "You can run this deployment file using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O2UJoHmvza70"
   },
   "outputs": [],
   "source": [
    "! oc create -f deployment.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lxe5gDSKFEeR"
   },
   "source": [
    "View running pods in namespace 'default'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kpRf3b_rFOd5"
   },
   "outputs": [],
   "source": [
    "! oc get pods --namespace default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tj4uWLEtFTAz"
   },
   "source": [
    "View logs from the application pod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SPS8HSv0FcaT"
   },
   "outputs": [],
   "source": [
    "! oc logs -f metropolis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zWcwmj8_yCbS"
   },
   "source": [
    "Optimizing fine-tuned BERT QA model to TensorRT (TRT)\n",
    "\n",
    "Steps:\n",
    "\n",
    "#### 1. Clone TensorRT Github repository on OCP node: https://github.com/NVIDIA/TensorRT.git\n",
    "\n",
    "#### 2. We'll use TensorRT container from NGC: https://ngc.nvidia.com/catalog/containers/nvidia:tensorrt \n",
    "\n",
    "  This container does not come preinstalled with all the python dependencies. Please install the dependencies by executing the following command from within the container: \n",
    "\n",
    "`\n",
    "/opt/tensorrt/python/python_setup.sh \n",
    "`\n",
    "\n",
    "#### 3. We'll be using /TensorRT/demo/BERT/builder.py script to build our optimized TensorRT engine with the following arguments:\n",
    "\n",
    "\n",
    "```\n",
    "mkdir -p /home/engines && \\                     # Make dir to save model\n",
    "python3 builder.py \\                            # Python script to build TRT engine\n",
    "-m /home/bert-fine-tuned/model.ckpt-8144 \\      # Fine-tuned BERT model\n",
    "-o /home/engines/bert_large_128.engine \\        # Output dir where TRT engine will be stored\n",
    "-b 1 \\                                          # Batch size\n",
    "-s 128 \\                                        # Sequence length\n",
    "--fp32 \\                                        # Precision\n",
    "-c /home/bert-fine-tuned/                       # Config dir\n",
    "\n",
    "```\n",
    "\n",
    "Now we are ready to package the above steps in a yaml for deployment on OCP. We can use the same yaml used for training by modifying the image and command to run in the pod.\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "apiVersion: v1\n",
    "kind: Pod\n",
    "metadata:\n",
    "  name: trt\n",
    "  namespace: default\n",
    "spec:\n",
    "  restartPolicy: OnFailure\n",
    "  containers:\n",
    "    - name: trt\n",
    "      image: \"nvcr.io/nvidia/tensorrt:20.09-py3\"\n",
    "      command: [\"/bin/bash\", \"-ec\", \" bash /opt/tensorrt/python/python_setup.sh; cd /home/TensorRT/demo/BERT; mkdir -p /home/engines && python3 builder.py -m /home/bert-fine-tuned/model.ckpt-8144 -o /home/engines/bert_large_128.engine -b 1 -s 128 --fp32 -c /home/bert-fine-tuned/;\"]\n",
    "      env:\n",
    "        - name: NVIDIA_VISIBLE_DEVICES\n",
    "          value: all\n",
    "        - name: NVIDIA_DRIVER_CAPABILITIES\n",
    "          value: \"compute,utility\"\n",
    "        - name: NVIDIA_REQUIRE_CUDA\n",
    "          value: \"cuda>=5.0\"\n",
    "      securityContext:\n",
    "        privileged: true\n",
    "      resources:\n",
    "        limits:\n",
    "          nvidia.com/gpu: 1 # requesting 1 GPU\n",
    "      volumeMounts:\n",
    "      - mountPath: /home\n",
    "        name: ocs-ml-data\n",
    "  volumes:\n",
    "  - name: ocs-ml-data\n",
    "    persistentVolumeClaim:\n",
    "      # directory location on host\n",
    "      claimName: ocs-ml-data\n",
    "      readOnly: false\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G7cpirMq6K6q"
   },
   "outputs": [],
   "source": [
    "! oc create -f trt_export.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QEelIOh7qN4"
   },
   "source": [
    "Let's check the status of the pod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AQxDIWNg7veI"
   },
   "outputs": [],
   "source": [
    "! oc get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFrzRhnx71Er"
   },
   "source": [
    "Finally, let's check the logs and make sure the engine is created in the output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sY6xUdJj78MX"
   },
   "outputs": [],
   "source": [
    "! oc logs trt"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "bert_squad_tf_finetuning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
